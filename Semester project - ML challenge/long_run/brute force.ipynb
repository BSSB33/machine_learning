{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3810jvsc74a57bd0657860dc7bb60c6195b6cc4f6629a2afdbaf664588d761829adb0943c623b00a",
   "display_name": "Python 3.8.10 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "657860dc7bb60c6195b6cc4f6629a2afdbaf664588d761829adb0943c623b00a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from pandas import read_csv\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest,chi2,RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      C1   C2   C3  C4  C5   C6   C7   C8  C9 C10  ...    X11    X12    X13  \\\n",
       "0     V1   V1   V1  V1  V1   V1   V1   V1  V1  V1  ... -0.619 -0.536 -0.092   \n",
       "1     V1   V1   V1  V1  V1   V1   V2   V1  V3  V5  ...  0.352  0.073 -0.092   \n",
       "2     V1   V1   V1  V1  V1   V1   V1   V1  V2  V2  ... -1.933 -0.536 -0.092   \n",
       "3     V1   V1   V1  V1  V1   V1   V1   V1  V2  V2  ... -0.762 -0.536 -0.092   \n",
       "4     V1   V1   V1  V1  V1   V1   V1   V1  V1  V1  ... -0.505 -0.536 -0.092   \n",
       "..   ...  ...  ...  ..  ..  ...  ...  ...  ..  ..  ...    ...    ...    ...   \n",
       "395  NaN  NaN  NaN  V3  V1  NaN  NaN  NaN  V1  V4  ...    NaN    NaN    NaN   \n",
       "396  NaN  NaN  NaN  V3  V2  NaN  NaN   V1  V3  V2  ...    NaN    NaN    NaN   \n",
       "397  NaN  NaN  NaN  V3  V2  NaN  NaN  NaN  V1  V4  ...    NaN    NaN    NaN   \n",
       "398  NaN  NaN  NaN  V3  V1  NaN  NaN  NaN  V1  V8  ...    NaN    NaN    NaN   \n",
       "399  NaN  NaN  NaN  V3  V1  NaN  NaN   V1  V3  V2  ...    NaN    NaN    NaN   \n",
       "\n",
       "       X14    X15    X16    X17    X18    X19  Y  \n",
       "0    0.182  0.034 -0.172  0.401  0.393  0.216  1  \n",
       "1    1.098  0.034  1.160  0.401  0.037  0.216  1  \n",
       "2    1.098  0.034  0.716  0.401  0.724  0.216 -1  \n",
       "3    1.098  0.034  0.716  0.401  0.712  0.216 -1  \n",
       "4    0.182  0.034  0.716  0.401  0.393  0.216  1  \n",
       "..     ...    ...    ...    ...    ...    ... ..  \n",
       "395 -2.568  0.034    NaN  0.401  1.890  0.216  1  \n",
       "396 -4.401 -2.684    NaN  0.401  1.391  0.216  1  \n",
       "397  0.548  4.926    NaN  0.401  0.992  0.216  1  \n",
       "398 -1.651  3.567    NaN  0.401  0.992  0.216  1  \n",
       "399  0.182  0.034    NaN  0.401  1.012  0.216  1  \n",
       "\n",
       "[400 rows x 34 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>C1</th>\n      <th>C2</th>\n      <th>C3</th>\n      <th>C4</th>\n      <th>C5</th>\n      <th>C6</th>\n      <th>C7</th>\n      <th>C8</th>\n      <th>C9</th>\n      <th>C10</th>\n      <th>...</th>\n      <th>X11</th>\n      <th>X12</th>\n      <th>X13</th>\n      <th>X14</th>\n      <th>X15</th>\n      <th>X16</th>\n      <th>X17</th>\n      <th>X18</th>\n      <th>X19</th>\n      <th>Y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>...</td>\n      <td>-0.619</td>\n      <td>-0.536</td>\n      <td>-0.092</td>\n      <td>0.182</td>\n      <td>0.034</td>\n      <td>-0.172</td>\n      <td>0.401</td>\n      <td>0.393</td>\n      <td>0.216</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V2</td>\n      <td>V1</td>\n      <td>V3</td>\n      <td>V5</td>\n      <td>...</td>\n      <td>0.352</td>\n      <td>0.073</td>\n      <td>-0.092</td>\n      <td>1.098</td>\n      <td>0.034</td>\n      <td>1.160</td>\n      <td>0.401</td>\n      <td>0.037</td>\n      <td>0.216</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V2</td>\n      <td>V2</td>\n      <td>...</td>\n      <td>-1.933</td>\n      <td>-0.536</td>\n      <td>-0.092</td>\n      <td>1.098</td>\n      <td>0.034</td>\n      <td>0.716</td>\n      <td>0.401</td>\n      <td>0.724</td>\n      <td>0.216</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V2</td>\n      <td>V2</td>\n      <td>...</td>\n      <td>-0.762</td>\n      <td>-0.536</td>\n      <td>-0.092</td>\n      <td>1.098</td>\n      <td>0.034</td>\n      <td>0.716</td>\n      <td>0.401</td>\n      <td>0.712</td>\n      <td>0.216</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>...</td>\n      <td>-0.505</td>\n      <td>-0.536</td>\n      <td>-0.092</td>\n      <td>0.182</td>\n      <td>0.034</td>\n      <td>0.716</td>\n      <td>0.401</td>\n      <td>0.393</td>\n      <td>0.216</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>395</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>V3</td>\n      <td>V1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>V1</td>\n      <td>V4</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-2.568</td>\n      <td>0.034</td>\n      <td>NaN</td>\n      <td>0.401</td>\n      <td>1.890</td>\n      <td>0.216</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>396</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>V3</td>\n      <td>V2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>V1</td>\n      <td>V3</td>\n      <td>V2</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-4.401</td>\n      <td>-2.684</td>\n      <td>NaN</td>\n      <td>0.401</td>\n      <td>1.391</td>\n      <td>0.216</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>397</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>V3</td>\n      <td>V2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>V1</td>\n      <td>V4</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.548</td>\n      <td>4.926</td>\n      <td>NaN</td>\n      <td>0.401</td>\n      <td>0.992</td>\n      <td>0.216</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>398</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>V3</td>\n      <td>V1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>V1</td>\n      <td>V8</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-1.651</td>\n      <td>3.567</td>\n      <td>NaN</td>\n      <td>0.401</td>\n      <td>0.992</td>\n      <td>0.216</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>399</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>V3</td>\n      <td>V1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>V1</td>\n      <td>V3</td>\n      <td>V2</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.182</td>\n      <td>0.034</td>\n      <td>NaN</td>\n      <td>0.401</td>\n      <td>1.012</td>\n      <td>0.216</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>400 rows × 34 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "df = pd.read_csv(\"train.csv\", header=None)\n",
    "new_cols = ['C' + str(i) for i in range(1, 14 + 1)] + ['X' + str(i) for i in range(1, 19 + 2)]\n",
    "new_cols[-1] = 'Y'\n",
    "df.columns = new_cols\n",
    "\n",
    "features = df.loc[:, df.columns != 'Y']\n",
    "numerical_features = df.select_dtypes(include=['float64']).columns\n",
    "categorical_features = df.select_dtypes(include=['object']).columns\n",
    "target = df['Y']\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "68.77637130801688\n"
     ]
    }
   ],
   "source": [
    "print((np.count_nonzero(target == 1)/np.count_nonzero(target == -1)) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\BALU\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\impute\\_iterative.py:685: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n  warnings.warn(\"[IterativeImputer] Early stopping criterion not\"\nC:\\Users\\BALU\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(loc, value[:, i].tolist(), pi)\nC:\\Users\\BALU\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(loc, value[:, i].tolist(), pi)\nC:\\Users\\BALU\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(loc, value[:, i].tolist(), pi)\nC:\\Users\\BALU\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "#TODO Experiment with strategies\n",
    "iterative_numerical_imputer = IterativeImputer(max_iter=10)\n",
    "iterative_numerical_imputer.fit(X_train[numerical_features])\n",
    "X_train.loc[:, numerical_features] = iterative_numerical_imputer.transform(X_train.loc[:, numerical_features])\n",
    "X_test.loc[:, numerical_features] = iterative_numerical_imputer.transform(X_test.loc[:, numerical_features])\n",
    "\n",
    "categorical_imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "categorical_imputer.fit(X_train[categorical_features])\n",
    "X_train.loc[:, categorical_features] = categorical_imputer.transform(X_train.loc[:, categorical_features])\n",
    "X_test.loc[:, categorical_features] = categorical_imputer.transform(X_test.loc[:, categorical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_len = len(X_train)\n",
    "X = pd.concat([X_train, X_test])\n",
    "X = pd.get_dummies(X)\n",
    "X_train = X[:X_train_len]\n",
    "X_test = X[X_train_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X.to_csv(\"save\\X.csv\", index=False)\n",
    "#X_train.to_csv(\"save\\X_train.csv\", index=False)\n",
    "#X_test.to_csv(\"save\\X_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ">BAG 0.803 (0.037)\n",
      "> RF 0.808 (0.049)\n",
      "> ET 0.824 (0.050)\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(X_train, y_train, X_test, y_test, model):\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "\t#model.fit(X_train, y_train)\n",
    "\treturn cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "models, names = list(), list()\n",
    "# SVM\n",
    "#models.append(SVC(gamma='auto'))\n",
    "#names.append('SVM')\n",
    "# KNN\n",
    "#models.append(KNeighborsClassifier())\n",
    "#names.append('KNN')\n",
    "# Neutral Network\n",
    "#models.append(MLPClassifier(solver = 'adam', max_iter=1000, tol=0.000001, early_stopping=True, validation_fraction=0.1, n_iter_no_change=20))\n",
    "#names.append('NEU')\n",
    "# Bagging\n",
    "models.append(BaggingClassifier(n_estimators=1000))\n",
    "names.append('BAG')\n",
    "# RF\n",
    "models.append(RandomForestClassifier(n_estimators=1000))\n",
    "names.append(' RF')\n",
    "# ET\n",
    "models.append(ExtraTreesClassifier(n_estimators=1000))\n",
    "names.append(' ET')\n",
    "\n",
    "\n",
    "results = list()\n",
    "for i in range(len(models)):\n",
    "\tscores = evaluate_model(X_train, y_train, X_test, y_test, models[i])\n",
    "\tresults.append(scores)\n",
    "\tprint('>%s %.3f (%.3f)' % (names[i], scores.mean(), scores.std()))\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'n_estimators': [1000, 1111, 1222, 1333, 1444, 1555, 1666, 1777, 1888, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': [int(x) for x in np.linspace(start = 1000, stop = 2000, num = 10)],\n",
    "               'max_features': ['auto', 'sqrt'],\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': [2, 5, 10],\n",
    "               'min_samples_leaf': [1, 2, 4],\n",
    "               'bootstrap': [True, False]}\n",
    "\n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Fitting 5 folds for each of 4320 candidates, totalling 21600 fits\n",
      "Elapsed time:  11701.365000247955  seconds, which is:  195.02275000413258  minutes\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "\n",
    "# Random search of parameters, using 3 fold cross validation, search across 100 different combinations, and use all available cores\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = random_grid, cv = 5, n_jobs = -1, verbose = 2)\n",
    "#rf_random = (estimator = rf, param_distributions = random_grid, n_iter = 1000, cv = 4, verbose=2, random_state=42, n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "start = time.time()\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "end = time.time()\n",
    "print(\"Elapsed time: \", end - start, \" seconds, which is: \", (end - start) / 60, \" minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'bootstrap': False,\n",
       " 'max_depth': 60,\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 1111}"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy = 0.80%.\nAccuracy = 0.86%.\nImprovement of 7.81%.\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, X_test, y_test):\n",
    "    score = model.score(X_test, y_test)\n",
    "    print('Accuracy = {:0.2f}%.'.format(score))\n",
    "    return score\n",
    "    \n",
    "base_model = RandomForestClassifier(n_estimators = 1000)\n",
    "base_model.fit(X_train, y_train)\n",
    "base_accuracy = evaluate(base_model, X_test, y_test)\n",
    "\n",
    "random_accuracy = evaluate(grid_search.best_estimator_, X_test, y_test)\n",
    "\n",
    "print('Improvement of {:0.2f}%.'.format( 100 * (random_accuracy - base_accuracy) / base_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the original Test Set\n",
    "test_to_predict = pd.read_csv(\"test.csv\", header=None)\n",
    "\n",
    "numerical_features = test_to_predict.select_dtypes(include=['float64']).columns\n",
    "categorical_features = test_to_predict.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_to_predict.loc[:, numerical_features] = iterative_numerical_imputer.transform(test_to_predict.loc[:, numerical_features])\n",
    "test_to_predict.loc[:, categorical_features] = categorical_imputer.transform(test_to_predict.loc[:, categorical_features])\n",
    "\n",
    "test_to_predict_len = len(test_to_predict)\n",
    "original = pd.concat([features, test_to_predict])\n",
    "original = pd.get_dummies(original)\n",
    "test_to_predict = X[:test_to_predict_len]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           X1     X2     X3     X4     X5     X6        X7        X8     X9  \\\n",
       "104 -1.663000  0.875  0.823  0.736 -0.070 -0.513 -0.099000 -0.844000  0.994   \n",
       "369  0.165547  0.627  0.348 -0.986  0.447 -0.513  0.997000 -0.008958 -0.071   \n",
       "329 -0.004000  0.875 -1.092 -0.282 -0.458 -0.513 -1.196000  0.689000  0.842   \n",
       "295  2.484000 -0.118 -1.567  0.892 -0.716  0.779 -1.196000  1.800000 -0.071   \n",
       "248 -1.110000 -0.986  1.312 -1.846 -0.458  0.133  0.038775 -0.844000  0.537   \n",
       "..        ...    ...    ...    ...    ...    ...       ...       ...    ...   \n",
       "349 -0.557000 -1.359  0.348 -0.360 -0.458 -0.513 -0.319000 -0.216000  0.537   \n",
       "232  0.272000  0.379  0.348 -1.064 -1.750 -0.513 -0.648000  1.507000 -0.984   \n",
       "80  -0.557000 -0.242 -0.617 -0.047 -0.587  1.425  0.339000 -0.844000  0.537   \n",
       "165 -1.110000  0.503  3.226 -0.282 -1.104 -1.159  0.120000 -0.844000  0.385   \n",
       "77   1.102000 -0.242 -0.127 -2.238 -1.104 -0.513 -0.099000 -0.026000 -0.223   \n",
       "\n",
       "          X10  ...  C12_V1  C12_V2  C12_V3  C13_V1  C13_V2  C13_V3  C13_V4  \\\n",
       "104  0.568000  ...       0       0       1       0       1       0       0   \n",
       "369 -0.014618  ...       0       0       1       1       0       0       0   \n",
       "329 -0.546000  ...       1       0       0       1       0       0       0   \n",
       "295 -1.445000  ...       1       0       0       1       0       0       0   \n",
       "248  1.234000  ...       1       0       0       1       0       0       0   \n",
       "..        ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "349 -0.438000  ...       1       0       0       1       0       0       0   \n",
       "232 -1.985000  ...       1       0       0       1       0       0       0   \n",
       "80   1.234000  ...       1       0       0       1       0       0       0   \n",
       "165  0.568000  ...       1       0       0       1       0       0       0   \n",
       "77  -0.007000  ...       1       0       0       1       0       0       0   \n",
       "\n",
       "     C13_V5  C14_V1  C14_V2  \n",
       "104       0       0       1  \n",
       "369       0       0       1  \n",
       "329       0       1       0  \n",
       "295       0       0       1  \n",
       "248       0       0       1  \n",
       "..      ...     ...     ...  \n",
       "349       0       1       0  \n",
       "232       0       1       0  \n",
       "80        0       1       0  \n",
       "165       0       0       1  \n",
       "77        0       0       1  \n",
       "\n",
       "[100 rows x 67 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>X1</th>\n      <th>X2</th>\n      <th>X3</th>\n      <th>X4</th>\n      <th>X5</th>\n      <th>X6</th>\n      <th>X7</th>\n      <th>X8</th>\n      <th>X9</th>\n      <th>X10</th>\n      <th>...</th>\n      <th>C12_V1</th>\n      <th>C12_V2</th>\n      <th>C12_V3</th>\n      <th>C13_V1</th>\n      <th>C13_V2</th>\n      <th>C13_V3</th>\n      <th>C13_V4</th>\n      <th>C13_V5</th>\n      <th>C14_V1</th>\n      <th>C14_V2</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>104</th>\n      <td>-1.663000</td>\n      <td>0.875</td>\n      <td>0.823</td>\n      <td>0.736</td>\n      <td>-0.070</td>\n      <td>-0.513</td>\n      <td>-0.099000</td>\n      <td>-0.844000</td>\n      <td>0.994</td>\n      <td>0.568000</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>369</th>\n      <td>0.165547</td>\n      <td>0.627</td>\n      <td>0.348</td>\n      <td>-0.986</td>\n      <td>0.447</td>\n      <td>-0.513</td>\n      <td>0.997000</td>\n      <td>-0.008958</td>\n      <td>-0.071</td>\n      <td>-0.014618</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>329</th>\n      <td>-0.004000</td>\n      <td>0.875</td>\n      <td>-1.092</td>\n      <td>-0.282</td>\n      <td>-0.458</td>\n      <td>-0.513</td>\n      <td>-1.196000</td>\n      <td>0.689000</td>\n      <td>0.842</td>\n      <td>-0.546000</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>295</th>\n      <td>2.484000</td>\n      <td>-0.118</td>\n      <td>-1.567</td>\n      <td>0.892</td>\n      <td>-0.716</td>\n      <td>0.779</td>\n      <td>-1.196000</td>\n      <td>1.800000</td>\n      <td>-0.071</td>\n      <td>-1.445000</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>248</th>\n      <td>-1.110000</td>\n      <td>-0.986</td>\n      <td>1.312</td>\n      <td>-1.846</td>\n      <td>-0.458</td>\n      <td>0.133</td>\n      <td>0.038775</td>\n      <td>-0.844000</td>\n      <td>0.537</td>\n      <td>1.234000</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>349</th>\n      <td>-0.557000</td>\n      <td>-1.359</td>\n      <td>0.348</td>\n      <td>-0.360</td>\n      <td>-0.458</td>\n      <td>-0.513</td>\n      <td>-0.319000</td>\n      <td>-0.216000</td>\n      <td>0.537</td>\n      <td>-0.438000</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>232</th>\n      <td>0.272000</td>\n      <td>0.379</td>\n      <td>0.348</td>\n      <td>-1.064</td>\n      <td>-1.750</td>\n      <td>-0.513</td>\n      <td>-0.648000</td>\n      <td>1.507000</td>\n      <td>-0.984</td>\n      <td>-1.985000</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>80</th>\n      <td>-0.557000</td>\n      <td>-0.242</td>\n      <td>-0.617</td>\n      <td>-0.047</td>\n      <td>-0.587</td>\n      <td>1.425</td>\n      <td>0.339000</td>\n      <td>-0.844000</td>\n      <td>0.537</td>\n      <td>1.234000</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>165</th>\n      <td>-1.110000</td>\n      <td>0.503</td>\n      <td>3.226</td>\n      <td>-0.282</td>\n      <td>-1.104</td>\n      <td>-1.159</td>\n      <td>0.120000</td>\n      <td>-0.844000</td>\n      <td>0.385</td>\n      <td>0.568000</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>77</th>\n      <td>1.102000</td>\n      <td>-0.242</td>\n      <td>-0.127</td>\n      <td>-2.238</td>\n      <td>-1.104</td>\n      <td>-0.513</td>\n      <td>-0.099000</td>\n      <td>-0.026000</td>\n      <td>-0.223</td>\n      <td>-0.007000</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>100 rows × 67 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "test_to_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Count(1):  34 Count(-1):  66\n51.515151515151516\n"
     ]
    }
   ],
   "source": [
    "prediction = grid_search.best_estimator_.predict(test_to_predict)\n",
    "print(\"Count(1): \", np.count_nonzero(prediction == 1), \"Count(-1): \", np.count_nonzero(prediction == -1))\n",
    "print((np.count_nonzero(prediction == 1)/np.count_nonzero(prediction == -1)) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting\n",
    "prediction = pd.DataFrame(prediction)\n",
    "prediction.to_csv(\"predictions.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO https://datascience.stackexchange.com/questions/75345/need-help-understanding-data-leakage\n",
    "# TODO https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74"
   ]
  }
 ]
}