{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd02c829f9b014f45ac51ac6981ee268f80d78860744c6a50c09e5b990310b7d8d4",
   "display_name": "Python 3.8.8 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "2c829f9b014f45ac51ac6981ee268f80d78860744c6a50c09e5b990310b7d8d4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from pandas import read_csv\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest,chi2,RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   C1  C2  C3  C4  C5  C6  C7  C8  C9 C10  ...    X11    X12    X13    X14  \\\n",
       "0  V1  V1  V1  V1  V1  V1  V2  V1  V3  V5  ...  0.352  0.073 -0.092  1.098   \n",
       "1  V1  V1  V1  V1  V1  V1  V1  V1  V2  V2  ... -1.933 -0.536 -0.092  1.098   \n",
       "2  V1  V1  V1  V1  V1  V1  V1  V1  V2  V2  ... -0.762 -0.536 -0.092  1.098   \n",
       "3  V1  V1  V1  V1  V1  V1  V1  V1  V1  V1  ... -0.505 -0.536 -0.092  0.182   \n",
       "4  V1  V1  V1  V1  V1  V1  V1  V1  V1  V1  ...  0.409 -0.536 -0.092  0.731   \n",
       "\n",
       "     X15    X16    X17    X18    X19  Y  \n",
       "0  0.034  1.160  0.401  0.037  0.216  1  \n",
       "1  0.034  0.716  0.401  0.724  0.216 -1  \n",
       "2  0.034  0.716  0.401  0.712  0.216 -1  \n",
       "3  0.034  0.716  0.401  0.393  0.216  1  \n",
       "4  0.034  0.716  0.401  0.724  0.216  1  \n",
       "\n",
       "[5 rows x 34 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>C1</th>\n      <th>C2</th>\n      <th>C3</th>\n      <th>C4</th>\n      <th>C5</th>\n      <th>C6</th>\n      <th>C7</th>\n      <th>C8</th>\n      <th>C9</th>\n      <th>C10</th>\n      <th>...</th>\n      <th>X11</th>\n      <th>X12</th>\n      <th>X13</th>\n      <th>X14</th>\n      <th>X15</th>\n      <th>X16</th>\n      <th>X17</th>\n      <th>X18</th>\n      <th>X19</th>\n      <th>Y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V2</td>\n      <td>V1</td>\n      <td>V3</td>\n      <td>V5</td>\n      <td>...</td>\n      <td>0.352</td>\n      <td>0.073</td>\n      <td>-0.092</td>\n      <td>1.098</td>\n      <td>0.034</td>\n      <td>1.160</td>\n      <td>0.401</td>\n      <td>0.037</td>\n      <td>0.216</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V2</td>\n      <td>V2</td>\n      <td>...</td>\n      <td>-1.933</td>\n      <td>-0.536</td>\n      <td>-0.092</td>\n      <td>1.098</td>\n      <td>0.034</td>\n      <td>0.716</td>\n      <td>0.401</td>\n      <td>0.724</td>\n      <td>0.216</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V2</td>\n      <td>V2</td>\n      <td>...</td>\n      <td>-0.762</td>\n      <td>-0.536</td>\n      <td>-0.092</td>\n      <td>1.098</td>\n      <td>0.034</td>\n      <td>0.716</td>\n      <td>0.401</td>\n      <td>0.712</td>\n      <td>0.216</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>...</td>\n      <td>-0.505</td>\n      <td>-0.536</td>\n      <td>-0.092</td>\n      <td>0.182</td>\n      <td>0.034</td>\n      <td>0.716</td>\n      <td>0.401</td>\n      <td>0.393</td>\n      <td>0.216</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>...</td>\n      <td>0.409</td>\n      <td>-0.536</td>\n      <td>-0.092</td>\n      <td>0.731</td>\n      <td>0.034</td>\n      <td>0.716</td>\n      <td>0.401</td>\n      <td>0.724</td>\n      <td>0.216</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 34 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 184
    }
   ],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "new_cols = ['C' + str(i) for i in range(1, 14 + 1)] + ['X' + str(i) for i in range(1, 19 + 2)]\n",
    "new_cols[-1] = 'Y'\n",
    "df.columns = new_cols[:num_cols]\n",
    "# -1 = not happening (negative), 1 = happening (positive)\n",
    "#df['Y'].replace({-1 : 0}, inplace=True, regex=True)\n",
    "\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.loc[:, df.columns != 'Y']\n",
    "numerical_features = df.select_dtypes(include=['float64']).columns\n",
    "categorical_features = df.select_dtypes(include=['object']).columns\n",
    "target = df['Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "numerical_imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "numerical_imputer.fit(df[numerical_features])\n",
    "df[numerical_features] = numerical_imputer.transform(df[numerical_features])\n",
    "\n",
    "categorical_imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "categorical_imputer.fit(df[categorical_features])\n",
    "df[categorical_features] = categorical_imputer.transform(df[categorical_features])\n",
    "\n",
    "encoded_df = pd.get_dummies(df).astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df.to_csv(\"export.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "X1        int64\n",
       "X2        int64\n",
       "X3        int64\n",
       "X4        int64\n",
       "X5        int64\n",
       "          ...  \n",
       "C13_V3    int64\n",
       "C13_V4    int64\n",
       "C13_V5    int64\n",
       "C14_V1    int64\n",
       "C14_V2    int64\n",
       "Length: 68, dtype: object"
      ]
     },
     "metadata": {},
     "execution_count": 200
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(encoded_df, labels, test_size=0.3)"
   ]
  }
 ]
}