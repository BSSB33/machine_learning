{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd02c829f9b014f45ac51ac6981ee268f80d78860744c6a50c09e5b990310b7d8d4",
   "display_name": "Python 3.8.8 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "2c829f9b014f45ac51ac6981ee268f80d78860744c6a50c09e5b990310b7d8d4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from pandas import read_csv\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest,chi2,RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      C1   C2   C3  C4  C5   C6   C7   C8  C9 C10  ...    X11    X12    X13  \\\n",
       "0     V1   V1   V1  V1  V1   V1   V2   V1  V3  V5  ...  0.352  0.073 -0.092   \n",
       "1     V1   V1   V1  V1  V1   V1   V1   V1  V2  V2  ... -1.933 -0.536 -0.092   \n",
       "2     V1   V1   V1  V1  V1   V1   V1   V1  V2  V2  ... -0.762 -0.536 -0.092   \n",
       "3     V1   V1   V1  V1  V1   V1   V1   V1  V1  V1  ... -0.505 -0.536 -0.092   \n",
       "4     V1   V1   V1  V1  V1   V1   V1   V1  V1  V1  ...  0.409 -0.536 -0.092   \n",
       "..   ...  ...  ...  ..  ..  ...  ...  ...  ..  ..  ...    ...    ...    ...   \n",
       "394  NaN  NaN  NaN  V3  V1  NaN  NaN  NaN  V1  V4  ...    NaN    NaN    NaN   \n",
       "395  NaN  NaN  NaN  V3  V2  NaN  NaN   V1  V3  V2  ...    NaN    NaN    NaN   \n",
       "396  NaN  NaN  NaN  V3  V2  NaN  NaN  NaN  V1  V4  ...    NaN    NaN    NaN   \n",
       "397  NaN  NaN  NaN  V3  V1  NaN  NaN  NaN  V1  V8  ...    NaN    NaN    NaN   \n",
       "398  NaN  NaN  NaN  V3  V1  NaN  NaN   V1  V3  V2  ...    NaN    NaN    NaN   \n",
       "\n",
       "       X14    X15    X16    X17    X18    X19  Y  \n",
       "0    1.098  0.034  1.160  0.401  0.037  0.216  1  \n",
       "1    1.098  0.034  0.716  0.401  0.724  0.216 -1  \n",
       "2    1.098  0.034  0.716  0.401  0.712  0.216 -1  \n",
       "3    0.182  0.034  0.716  0.401  0.393  0.216  1  \n",
       "4    0.731  0.034  0.716  0.401  0.724  0.216  1  \n",
       "..     ...    ...    ...    ...    ...    ... ..  \n",
       "394 -2.568  0.034    NaN  0.401  1.890  0.216  1  \n",
       "395 -4.401 -2.684    NaN  0.401  1.391  0.216  1  \n",
       "396  0.548  4.926    NaN  0.401  0.992  0.216  1  \n",
       "397 -1.651  3.567    NaN  0.401  0.992  0.216  1  \n",
       "398  0.182  0.034    NaN  0.401  1.012  0.216  1  \n",
       "\n",
       "[399 rows x 34 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>C1</th>\n      <th>C2</th>\n      <th>C3</th>\n      <th>C4</th>\n      <th>C5</th>\n      <th>C6</th>\n      <th>C7</th>\n      <th>C8</th>\n      <th>C9</th>\n      <th>C10</th>\n      <th>...</th>\n      <th>X11</th>\n      <th>X12</th>\n      <th>X13</th>\n      <th>X14</th>\n      <th>X15</th>\n      <th>X16</th>\n      <th>X17</th>\n      <th>X18</th>\n      <th>X19</th>\n      <th>Y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V2</td>\n      <td>V1</td>\n      <td>V3</td>\n      <td>V5</td>\n      <td>...</td>\n      <td>0.352</td>\n      <td>0.073</td>\n      <td>-0.092</td>\n      <td>1.098</td>\n      <td>0.034</td>\n      <td>1.160</td>\n      <td>0.401</td>\n      <td>0.037</td>\n      <td>0.216</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V2</td>\n      <td>V2</td>\n      <td>...</td>\n      <td>-1.933</td>\n      <td>-0.536</td>\n      <td>-0.092</td>\n      <td>1.098</td>\n      <td>0.034</td>\n      <td>0.716</td>\n      <td>0.401</td>\n      <td>0.724</td>\n      <td>0.216</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V2</td>\n      <td>V2</td>\n      <td>...</td>\n      <td>-0.762</td>\n      <td>-0.536</td>\n      <td>-0.092</td>\n      <td>1.098</td>\n      <td>0.034</td>\n      <td>0.716</td>\n      <td>0.401</td>\n      <td>0.712</td>\n      <td>0.216</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>...</td>\n      <td>-0.505</td>\n      <td>-0.536</td>\n      <td>-0.092</td>\n      <td>0.182</td>\n      <td>0.034</td>\n      <td>0.716</td>\n      <td>0.401</td>\n      <td>0.393</td>\n      <td>0.216</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>...</td>\n      <td>0.409</td>\n      <td>-0.536</td>\n      <td>-0.092</td>\n      <td>0.731</td>\n      <td>0.034</td>\n      <td>0.716</td>\n      <td>0.401</td>\n      <td>0.724</td>\n      <td>0.216</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>394</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>V3</td>\n      <td>V1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>V1</td>\n      <td>V4</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-2.568</td>\n      <td>0.034</td>\n      <td>NaN</td>\n      <td>0.401</td>\n      <td>1.890</td>\n      <td>0.216</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>395</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>V3</td>\n      <td>V2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>V1</td>\n      <td>V3</td>\n      <td>V2</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-4.401</td>\n      <td>-2.684</td>\n      <td>NaN</td>\n      <td>0.401</td>\n      <td>1.391</td>\n      <td>0.216</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>396</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>V3</td>\n      <td>V2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>V1</td>\n      <td>V4</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.548</td>\n      <td>4.926</td>\n      <td>NaN</td>\n      <td>0.401</td>\n      <td>0.992</td>\n      <td>0.216</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>397</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>V3</td>\n      <td>V1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>V1</td>\n      <td>V8</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-1.651</td>\n      <td>3.567</td>\n      <td>NaN</td>\n      <td>0.401</td>\n      <td>0.992</td>\n      <td>0.216</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>398</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>V3</td>\n      <td>V1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>V1</td>\n      <td>V3</td>\n      <td>V2</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.182</td>\n      <td>0.034</td>\n      <td>NaN</td>\n      <td>0.401</td>\n      <td>1.012</td>\n      <td>0.216</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>399 rows × 34 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 115
    }
   ],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "new_cols = ['C' + str(i) for i in range(1, 14 + 1)] + ['X' + str(i) for i in range(1, 19 + 2)]\n",
    "new_cols[-1] = 'Y'\n",
    "df.columns = new_cols\n",
    "\n",
    "features = df.loc[:, df.columns != 'Y']\n",
    "numerical_features = df.select_dtypes(include=['float64']).columns\n",
    "categorical_features = df.select_dtypes(include=['object']).columns\n",
    "target = df['Y']\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Gábor\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\impute\\_iterative.py:685: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n  warnings.warn(\"[IterativeImputer] Early stopping criterion not\"\nC:\\Users\\Gábor\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(loc, value[:, i].tolist(), pi)\nC:\\Users\\Gábor\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(loc, value[:, i].tolist(), pi)\nC:\\Users\\Gábor\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(loc, value[:, i].tolist(), pi)\nC:\\Users\\Gábor\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "#TODO Experiment with strategies\n",
    "iterative_numerical_imputer = IterativeImputer(max_iter=10)\n",
    "iterative_numerical_imputer.fit(X_train[numerical_features])\n",
    "X_train.loc[:, numerical_features] = iterative_numerical_imputer.transform(X_train.loc[:, numerical_features])\n",
    "X_test.loc[:, numerical_features] = iterative_numerical_imputer.transform(X_test.loc[:, numerical_features])\n",
    "\n",
    "categorical_imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "categorical_imputer.fit(X_train[categorical_features])\n",
    "X_train.loc[:, categorical_features] = categorical_imputer.transform(X_train.loc[:, categorical_features])\n",
    "X_test.loc[:, categorical_features] = categorical_imputer.transform(X_test.loc[:, categorical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_len = len(X_train)\n",
    "X = pd.concat([X_train, X_test])\n",
    "X = pd.get_dummies(X)\n",
    "X_train = X[:X_train_len]\n",
    "X_test = X[X_train_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X.to_csv(\"save\\X.csv\", index=False)\n",
    "#X_train.to_csv(\"save\\X_train.csv\", index=False)\n",
    "#X_test.to_csv(\"save\\X_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(n_estimators=1000)"
      ]
     },
     "metadata": {},
     "execution_count": 134
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "classifier1 = RandomForestClassifier(n_estimators=1000)\n",
    "classifier2 = ExtraTreesClassifier(n_estimators=1000)\n",
    "\n",
    "classifier1.fit(X_train, y_train)\n",
    "classifier2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "RandomForestClassifier\n[[41  1]\n [ 8 30]]\n              precision    recall  f1-score   support\n\n          -1       0.84      0.98      0.90        42\n           1       0.97      0.79      0.87        38\n\n    accuracy                           0.89        80\n   macro avg       0.90      0.88      0.89        80\nweighted avg       0.90      0.89      0.89        80\n\nExtraTreesClassifier\n[[40  2]\n [ 6 32]]\n              precision    recall  f1-score   support\n\n          -1       0.87      0.95      0.91        42\n           1       0.94      0.84      0.89        38\n\n    accuracy                           0.90        80\n   macro avg       0.91      0.90      0.90        80\nweighted avg       0.90      0.90      0.90        80\n\n"
     ]
    }
   ],
   "source": [
    "y_pred1 = classifier1.predict(X_test)\n",
    "y_pred2 = classifier2.predict(X_test)\n",
    "\n",
    "cm1 = confusion_matrix(y_test, y_pred1)\n",
    "cm2 = confusion_matrix(y_test, y_pred2)\n",
    "print(\"RandomForestClassifier\")\n",
    "print(cm1)\n",
    "print(classification_report(y_test, y_pred1))\n",
    "\n",
    "print(\"ExtraTreesClassifier\")\n",
    "print(cm2)\n",
    "print(classification_report(y_test, y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mean Absolute Error: 0.275\nMean Squared Error: 0.55\nRoot Mean Squared Error: 0.7416198487095663\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print('Mean Absolute Error:', metrics.mean_absolute_error(y_test, y_pred))\n",
    "print('Mean Squared Error:', metrics.mean_squared_error(y_test, y_pred))\n",
    "print('Root Mean Squared Error:', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"\\nresults = list()\\nfor i in range(len(models)):\\n\\tscores = evaluate_model(X_train, y_train, X_test, y_test, models[i])\\n\\tresults.append(scores)\\n\\tprint('>%s %.3f (%.3f)' % (names[i], scores.mean(), scores.std()))\\n\\t\""
      ]
     },
     "metadata": {},
     "execution_count": 123
    }
   ],
   "source": [
    "def evaluate_model(X_train, y_train, X_test, y_test, model):\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "\t#model.fit(X_train, y_train)\n",
    "\treturn cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "models, names = list(), list()\n",
    "# SVM\n",
    "models.append(SVC(gamma='auto'))\n",
    "names.append('SVM')\n",
    "# KNN\n",
    "models.append(KNeighborsClassifier())\n",
    "names.append('KNN')\n",
    "# Neutral Network\n",
    "models.append(MLPClassifier(solver = 'adam', max_iter=1000, tol=0.000001, early_stopping=True, validation_fraction=0.1, n_iter_no_change=20))\n",
    "names.append('NEU')\n",
    "# Bagging\n",
    "models.append(BaggingClassifier(n_estimators=1000))\n",
    "names.append('BAG')\n",
    "# RF\n",
    "models.append(RandomForestClassifier(n_estimators=1000))\n",
    "names.append(' RF')\n",
    "# ET\n",
    "models.append(ExtraTreesClassifier(n_estimators=1000))\n",
    "names.append(' ET')\n",
    "\n",
    "\"\"\"\n",
    "results = list()\n",
    "for i in range(len(models)):\n",
    "\tscores = evaluate_model(X_train, y_train, X_test, y_test, models[i])\n",
    "\tresults.append(scores)\n",
    "\tprint('>%s %.3f (%.3f)' % (names[i], scores.mean(), scores.std()))\n",
    "\t\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\nclf = RandomForestClassifier()\\nclf.fit(X, target)\\n\\nplt.figure(figsize=(20,8))\\nplt.bar(X.columns, clf.feature_importances_)\\nplt.xticks(rotation=45)\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 124
    }
   ],
   "source": [
    "\"\"\"\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X, target)\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.bar(X.columns, clf.feature_importances_)\n",
    "plt.xticks(rotation=45)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GridSearchCV?\n",
    "# TODO https://datascience.stackexchange.com/questions/75345/need-help-understanding-data-leakage\n",
    "# TODO https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74"
   ]
  }
 ]
}