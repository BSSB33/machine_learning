{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python388jvsc74a57bd02c829f9b014f45ac51ac6981ee268f80d78860744c6a50c09e5b990310b7d8d4",
   "display_name": "Python 3.8.8 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "2c829f9b014f45ac51ac6981ee268f80d78860744c6a50c09e5b990310b7d8d4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from pandas import read_csv\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.feature_selection import SelectKBest,chi2,RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      C1   C2   C3  C4  C5   C6   C7   C8  C9 C10  ...    X11    X12    X13  \\\n",
       "0     V1   V1   V1  V1  V1   V1   V2   V1  V3  V5  ...  0.352  0.073 -0.092   \n",
       "1     V1   V1   V1  V1  V1   V1   V1   V1  V2  V2  ... -1.933 -0.536 -0.092   \n",
       "2     V1   V1   V1  V1  V1   V1   V1   V1  V2  V2  ... -0.762 -0.536 -0.092   \n",
       "3     V1   V1   V1  V1  V1   V1   V1   V1  V1  V1  ... -0.505 -0.536 -0.092   \n",
       "4     V1   V1   V1  V1  V1   V1   V1   V1  V1  V1  ...  0.409 -0.536 -0.092   \n",
       "..   ...  ...  ...  ..  ..  ...  ...  ...  ..  ..  ...    ...    ...    ...   \n",
       "394  NaN  NaN  NaN  V3  V1  NaN  NaN  NaN  V1  V4  ...    NaN    NaN    NaN   \n",
       "395  NaN  NaN  NaN  V3  V2  NaN  NaN   V1  V3  V2  ...    NaN    NaN    NaN   \n",
       "396  NaN  NaN  NaN  V3  V2  NaN  NaN  NaN  V1  V4  ...    NaN    NaN    NaN   \n",
       "397  NaN  NaN  NaN  V3  V1  NaN  NaN  NaN  V1  V8  ...    NaN    NaN    NaN   \n",
       "398  NaN  NaN  NaN  V3  V1  NaN  NaN   V1  V3  V2  ...    NaN    NaN    NaN   \n",
       "\n",
       "       X14    X15    X16    X17    X18    X19  Y  \n",
       "0    1.098  0.034  1.160  0.401  0.037  0.216  1  \n",
       "1    1.098  0.034  0.716  0.401  0.724  0.216 -1  \n",
       "2    1.098  0.034  0.716  0.401  0.712  0.216 -1  \n",
       "3    0.182  0.034  0.716  0.401  0.393  0.216  1  \n",
       "4    0.731  0.034  0.716  0.401  0.724  0.216  1  \n",
       "..     ...    ...    ...    ...    ...    ... ..  \n",
       "394 -2.568  0.034    NaN  0.401  1.890  0.216  1  \n",
       "395 -4.401 -2.684    NaN  0.401  1.391  0.216  1  \n",
       "396  0.548  4.926    NaN  0.401  0.992  0.216  1  \n",
       "397 -1.651  3.567    NaN  0.401  0.992  0.216  1  \n",
       "398  0.182  0.034    NaN  0.401  1.012  0.216  1  \n",
       "\n",
       "[399 rows x 34 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>C1</th>\n      <th>C2</th>\n      <th>C3</th>\n      <th>C4</th>\n      <th>C5</th>\n      <th>C6</th>\n      <th>C7</th>\n      <th>C8</th>\n      <th>C9</th>\n      <th>C10</th>\n      <th>...</th>\n      <th>X11</th>\n      <th>X12</th>\n      <th>X13</th>\n      <th>X14</th>\n      <th>X15</th>\n      <th>X16</th>\n      <th>X17</th>\n      <th>X18</th>\n      <th>X19</th>\n      <th>Y</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V2</td>\n      <td>V1</td>\n      <td>V3</td>\n      <td>V5</td>\n      <td>...</td>\n      <td>0.352</td>\n      <td>0.073</td>\n      <td>-0.092</td>\n      <td>1.098</td>\n      <td>0.034</td>\n      <td>1.160</td>\n      <td>0.401</td>\n      <td>0.037</td>\n      <td>0.216</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V2</td>\n      <td>V2</td>\n      <td>...</td>\n      <td>-1.933</td>\n      <td>-0.536</td>\n      <td>-0.092</td>\n      <td>1.098</td>\n      <td>0.034</td>\n      <td>0.716</td>\n      <td>0.401</td>\n      <td>0.724</td>\n      <td>0.216</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V2</td>\n      <td>V2</td>\n      <td>...</td>\n      <td>-0.762</td>\n      <td>-0.536</td>\n      <td>-0.092</td>\n      <td>1.098</td>\n      <td>0.034</td>\n      <td>0.716</td>\n      <td>0.401</td>\n      <td>0.712</td>\n      <td>0.216</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>...</td>\n      <td>-0.505</td>\n      <td>-0.536</td>\n      <td>-0.092</td>\n      <td>0.182</td>\n      <td>0.034</td>\n      <td>0.716</td>\n      <td>0.401</td>\n      <td>0.393</td>\n      <td>0.216</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>V1</td>\n      <td>...</td>\n      <td>0.409</td>\n      <td>-0.536</td>\n      <td>-0.092</td>\n      <td>0.731</td>\n      <td>0.034</td>\n      <td>0.716</td>\n      <td>0.401</td>\n      <td>0.724</td>\n      <td>0.216</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>394</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>V3</td>\n      <td>V1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>V1</td>\n      <td>V4</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-2.568</td>\n      <td>0.034</td>\n      <td>NaN</td>\n      <td>0.401</td>\n      <td>1.890</td>\n      <td>0.216</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>395</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>V3</td>\n      <td>V2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>V1</td>\n      <td>V3</td>\n      <td>V2</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-4.401</td>\n      <td>-2.684</td>\n      <td>NaN</td>\n      <td>0.401</td>\n      <td>1.391</td>\n      <td>0.216</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>396</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>V3</td>\n      <td>V2</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>V1</td>\n      <td>V4</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.548</td>\n      <td>4.926</td>\n      <td>NaN</td>\n      <td>0.401</td>\n      <td>0.992</td>\n      <td>0.216</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>397</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>V3</td>\n      <td>V1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>V1</td>\n      <td>V8</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>-1.651</td>\n      <td>3.567</td>\n      <td>NaN</td>\n      <td>0.401</td>\n      <td>0.992</td>\n      <td>0.216</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>398</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>V3</td>\n      <td>V1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>V1</td>\n      <td>V3</td>\n      <td>V2</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>0.182</td>\n      <td>0.034</td>\n      <td>NaN</td>\n      <td>0.401</td>\n      <td>1.012</td>\n      <td>0.216</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>399 rows × 34 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 142
    }
   ],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "new_cols = ['C' + str(i) for i in range(1, 14 + 1)] + ['X' + str(i) for i in range(1, 19 + 2)]\n",
    "new_cols[-1] = 'Y'\n",
    "df.columns = new_cols\n",
    "\n",
    "features = df.loc[:, df.columns != 'Y']\n",
    "numerical_features = df.select_dtypes(include=['float64']).columns\n",
    "categorical_features = df.select_dtypes(include=['object']).columns\n",
    "target = df['Y']\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Gábor\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\impute\\_iterative.py:685: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n  warnings.warn(\"[IterativeImputer] Early stopping criterion not\"\nC:\\Users\\Gábor\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(loc, value[:, i].tolist(), pi)\nC:\\Users\\Gábor\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(loc, value[:, i].tolist(), pi)\nC:\\Users\\Gábor\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(loc, value[:, i].tolist(), pi)\nC:\\Users\\Gábor\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\indexing.py:1738: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "#TODO Experiment with strategies\n",
    "iterative_numerical_imputer = IterativeImputer(max_iter=10)\n",
    "iterative_numerical_imputer.fit(X_train[numerical_features])\n",
    "X_train.loc[:, numerical_features] = iterative_numerical_imputer.transform(X_train.loc[:, numerical_features])\n",
    "X_test.loc[:, numerical_features] = iterative_numerical_imputer.transform(X_test.loc[:, numerical_features])\n",
    "\n",
    "categorical_imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "categorical_imputer.fit(X_train[categorical_features])\n",
    "X_train.loc[:, categorical_features] = categorical_imputer.transform(X_train.loc[:, categorical_features])\n",
    "X_test.loc[:, categorical_features] = categorical_imputer.transform(X_test.loc[:, categorical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_len = len(X_train)\n",
    "X = pd.concat([X_train, X_test])\n",
    "X = pd.get_dummies(X)\n",
    "X_train = X[:X_train_len]\n",
    "X_test = X[X_train_len:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'a\\\\X.csv'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-147-68127539b717>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"a\\X.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"a\\X_train.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"a\\X_test.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3385\u001b[0m         )\n\u001b[0;32m   3386\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3387\u001b[1;33m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[0;32m   3388\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3389\u001b[0m             \u001b[0mline_terminator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mline_terminator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\io\\formats\\format.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1081\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1082\u001b[0m         )\n\u001b[1;32m-> 1083\u001b[1;33m         \u001b[0mcsv_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1084\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1085\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    226\u001b[0m         \"\"\"\n\u001b[0;32m    227\u001b[0m         \u001b[1;31m# apply compression and byte/text conversion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m         with get_handle(\n\u001b[0m\u001b[0;32m    229\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'a\\\\X.csv'"
     ]
    }
   ],
   "source": [
    "X.to_csv(\"save\\X.csv\", index=False)\n",
    "X_train.to_csv(\"save\\X_train.csv\", index=False)\n",
    "X_test.to_csv(\"save\\X_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=1000)"
      ]
     },
     "metadata": {},
     "execution_count": 132
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators=1000)\n",
    "#classifier = ExtraTreesClassifier(n_estimators=1000)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[60  1]\n [24 35]]\n              precision    recall  f1-score   support\n\n          -1       0.71      0.98      0.83        61\n           1       0.97      0.59      0.74        59\n\n    accuracy                           0.79       120\n   macro avg       0.84      0.79      0.78       120\nweighted avg       0.84      0.79      0.78       120\n\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      ">SVM 0.725 (0.044)\n",
      ">KNN 0.750 (0.050)\n",
      ">BAG 0.778 (0.046)\n",
      "> RF 0.792 (0.037)\n",
      "> ET 0.820 (0.034)\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(X_train, y_train, X_test, y_test, model):\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "\t#model.fit(X_train, y_train)\n",
    "\treturn cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "models, names = list(), list()\n",
    "# SVM\n",
    "models.append(SVC(gamma='auto'))\n",
    "names.append('SVM')\n",
    "# KNN\n",
    "models.append(KNeighborsClassifier())\n",
    "names.append('KNN')\n",
    "# Bagging\n",
    "models.append(BaggingClassifier(n_estimators=1000))\n",
    "names.append('BAG')\n",
    "# RF\n",
    "models.append(RandomForestClassifier(n_estimators=1000))\n",
    "names.append(' RF')\n",
    "# ET\n",
    "models.append(ExtraTreesClassifier(n_estimators=1000))\n",
    "names.append(' ET')\n",
    "\n",
    "results = list()\n",
    "for i in range(len(models)):\n",
    "\tscores = evaluate_model(X_train, y_train, X_test, y_test, models[i])\n",
    "\tresults.append(scores)\n",
    "\tprint('>%s %.3f (%.3f)' % (names[i], scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'\\nclf = RandomForestClassifier()\\nclf.fit(encoded_features, target)\\n\\nplt.figure(figsize=(20,8))\\nplt.bar(encoded_features.columns, clf.feature_importances_)\\nplt.xticks(rotation=45)\\n'"
      ]
     },
     "metadata": {},
     "execution_count": 135
    }
   ],
   "source": [
    "\"\"\"\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(encoded_features, target)\n",
    "\n",
    "plt.figure(figsize=(20,8))\n",
    "plt.bar(encoded_features.columns, clf.feature_importances_)\n",
    "plt.xticks(rotation=45)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GridSearchCV?\n",
    "# TODO https://datascience.stackexchange.com/questions/75345/need-help-understanding-data-leakage"
   ]
  }
 ]
}